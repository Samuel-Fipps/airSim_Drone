Eval num_timesteps=1, episode_reward=68.19 +/- 0.00
Episode length: 172.00 +/- 0.00
New best mean reward!
Traceback (most recent call last):
  File "loading_main.py", line 103, in <module>
    loaded_model.learn(
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\ppo\ppo.py", line 299, in learn
    return super(PPO, self).learn(
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 250, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 184, in collect_rollouts
    if callback.on_step() is False:
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\callbacks.py", line 88, in on_step
    return self._on_step()
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\callbacks.py", line 192, in _on_step
    continue_training = callback.on_step() and continue_training
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\callbacks.py", line 88, in on_step
    return self._on_step()
  File "loading_main.py", line 25, in _on_step
    latest_results = self.eval_env.get_attr('episode_rewards')[-1]
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 287, in get_attr
    return self.venv.get_attr(attr_name, indices)
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 102, in get_attr
    return [getattr(env_i, attr_name) for env_i in target_envs]
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 102, in <listcomp>
    return [getattr(env_i, attr_name) for env_i in target_envs]
  File "C:\Users\cymstar_user\AppData\Local\Programs\Python\Python38\lib\site-packages\gym\core.py", line 218, in __getattr__
    return getattr(self.env, name)
AttributeError: 'AirSimDroneEnv' object has no attribute 'episode_rewards'